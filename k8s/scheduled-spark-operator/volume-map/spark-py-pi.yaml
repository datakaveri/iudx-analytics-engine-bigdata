apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: ScheduledSparkApplication
metadata:
  name: spark-pi-scheduled
  namespace: spark-operator
spec:
  schedule: "@every 1m" #*/1 * * * *
  concurrencyPolicy: Allow
  template:
    type: Python
    pythonVersion: "3"
    mode: cluster
    image: "gcr.io/spark-operator/spark-py:v3.1.1"
    imagePullPolicy: Always
    mainApplicationFile: local:///tmp/scripts/pi.py
    sparkVersion: "3.1.1"
    restartPolicy:
      type: OnFailure
      onFailureRetries: 3
      onFailureRetryInterval: 10
      onSubmissionFailureRetries: 5
      onSubmissionFailureRetryInterval: 20

    volumes:
      - name: test-volume
        hostPath:
          path: /mnt/scripts

    driver:
      cores: 1
      coreLimit: "1200m"
      memory: "512m"
      labels:
        version: 3.1.1
      volumeMounts:
      - mountPath: /tmp/scripts
        name: test-volume
      serviceAccount: default
    executor:
      cores: 1
      instances: 1
      memory: "512m"
      volumeMounts:
      - mountPath: /tmp/scripts
        name: test-volume
      labels:
        version: 3.1.1
